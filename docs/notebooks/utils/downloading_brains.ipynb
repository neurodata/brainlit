{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils.session import NeuroglancerSession\n",
    "import napari\n",
    "from napari.utils import nbscreenshot\n",
    "%gui qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Brain data tutorial\n",
    "We have prepared 2 brain volumes, as well as axon segment labels, at the below s3 urls (see uploading_brains.ipynb). The method demonstrated below pulls a region of the volume around an annotated axon point set by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Define Variables\n",
    "- mip ranges from higher resolution (0) to lower resolution (1).\n",
    "\n",
    "- v_id are vertex ids ranging from the soma (0) to the end of the axon (1649).\n",
    "\n",
    "- radius is the radius to pull around the selected point, in voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"s3://open-neurodata/brainlit/brain1\"\n",
    "dir_segments = \"s3://open-neurodata/brainlit/brain1_segments\"\n",
    "dir_2 = \"s3://open-neurodata/brainlit/brain2\"\n",
    "dir_2_segments = \"s3://open-neurodata/brainlit/brain2_segments\"\n",
    "mip = 0\n",
    "v_id = 0\n",
    "radius = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create a NeuroglancerSession instance and download the volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image and center point\n",
    "#ngl_sess = NeuroglancerSession(mip = mip, url = dir, url_segments=dir_segments,use_https=False)\n",
    "#img, bbox, vox = ngl_sess.pull_voxel(2, v_id, radius)\n",
    "#print(f\"\\n\\nDownloaded volume is of shape {img.shape}, with total intensity {sum(sum(sum(img)))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Generate a graph from the segment data within the volume, and convert it to paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G_paths = ngl_sess.get_segments(2, bbox)\n",
    "#G_sub = G_paths[0]\n",
    "#paths = G_paths[1]\n",
    "\n",
    "#print(f\"Selected volume contains {G_sub.number_of_nodes()} nodes and {len(paths)} paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) View the volume with paths overlaid via napari.Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewer = napari.Viewer(ndisplay=3)\n",
    "#viewer.add_image(img)\n",
    "#viewer.add_shapes(data=paths, shape_type='path', edge_width=0.1, edge_color='blue', opacity=0.1)\n",
    "#viewer.add_points(vox, size=1, opacity=0.5)\n",
    "#nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
