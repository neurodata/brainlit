{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('brainlit': conda)",
   "metadata": {
    "interpreter": {
     "hash": "23a6901d04df5a24b139bf940691d9158a219126a6bc30bd2116c3bca95057cb"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils.session import NeuroglancerSession\n",
    "from brainlit.utils.swc import graph_to_paths\n",
    "import napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Brain data tutorial\n",
    "We have prepared 2 brain volumes, as well as axon segment labels, at the below s3 urls (see `uploading_brains.ipynb`).\n",
    "The method demonstrated below pulls a region of the volume around an annotated axon point set by the user.\n",
    "\n",
    "## 1) Define Variables\n",
    "- `mip` ranges from higher resolution (0) to lower resolution (1).\n",
    "- `v_id` are vertex ids ranging from the soma (0) to the end of the axon (1649).\n",
    "- `radius` is the radius to pull around the selected point, in voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"s3://open-neurodata/brainlit/brain1\"\n",
    "dir_segments = \"s3://open-neurodata/brainlit/brain1_segments\"\n",
    "dir_2 = \"s3://open-neurodata/brainlit/brain2\"\n",
    "dir_2_segments = \"s3://open-neurodata/brainlit/brain2_segments\"\n",
    "mip = 0\n",
    "v_id = 0\n",
    "radius = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create a NeuroglancerSession instance and download the volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 1/1 [00:00<00:00, 10.00it/s]\n",
      "Downloading: 46it [00:01, 23.45it/s]\n",
      "\n",
      "Downloaded volume is of shape (151, 151, 151), with total intensity 4946609.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get image and center point\n",
    "ngl_sess = NeuroglancerSession(mip = mip, url = dir, url_segments=dir_segments)\n",
    "img, bbox, vox = ngl_sess.pull_voxel(2, v_id, radius)\n",
    "print(f\"\\n\\nDownloaded volume is of shape {img.shape}, with total intensity {sum(sum(sum(img)))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Generate a graph from the segment data within the volume, and convert it to paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "G_sub = ngl_sess.get_segments(2, bbox)\n",
    "paths = graph_to_paths(G_sub)\n",
    "print(f\"Selected volume contains {G_sub.number_of_nodes()} nodes and {len(paths)} paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) View the volume with paths overlaid via napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(img)\n",
    "    viewer.add_shapes(data=paths, shape_type='path', edge_width=0.1, edge_color='blue', opacity=0.1)\n",
    "    viewer.add_points(vox, size=1, opacity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}