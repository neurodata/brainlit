{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Neighborhoods Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: \n",
    "This tutorial covers how to perform visualize neighborhoods based on two approaches.  \n",
    "    \n",
    "    1) Grabbing a bounding box region a vertex\n",
    "    2) Grabbing n neighbors around a vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "%gui qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils.swc import *\n",
    "from brainlit.utils.ngl_pipeline import NeuroglancerSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "dest_dir = str(Path().resolve().parents[0] / \"utils\" / \"upload\")\n",
    "dest_dir_segments = str(Path().resolve().parents[0] / \"utils\" / \"upload_segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading data from s3 path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sample  structure      x      y      z    r  parent\n0       1          0  147.0  140.0  120.0  1.0      -1\n1       4        192  148.0  139.0  120.0  1.0       1\n2       7         64  148.0  139.0  120.0  1.0       4\n3       8          0  148.0  139.0  120.0  1.0       7\n4      14          0  148.0  139.0  121.0  1.0       8",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n      <th>structure</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>r</th>\n      <th>parent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>147.0</td>\n      <td>140.0</td>\n      <td>120.0</td>\n      <td>1.0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>192</td>\n      <td>148.0</td>\n      <td>139.0</td>\n      <td>120.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>64</td>\n      <td>148.0</td>\n      <td>139.0</td>\n      <td>120.0</td>\n      <td>1.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>0</td>\n      <td>148.0</td>\n      <td>139.0</td>\n      <td>120.0</td>\n      <td>1.0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14</td>\n      <td>0</td>\n      <td>148.0</td>\n      <td>139.0</td>\n      <td>121.0</td>\n      <td>1.0</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# s3_path = \"s3://mouse-light-viz/precomputed_volumes/brain1_segments\"\n",
    "s3_path = \"file://\"+dest_dir_segments\n",
    "seg_id,  v_id, mip = 2, 10, 1 # skeleton/neuron id, index/row of df, resolution quality\n",
    "df = read_s3(s3_path, seg_id, mip)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting dataframe to graph data structure to understand how vertices are connected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The graph was decomposed into 179 paths\n"
    }
   ],
   "source": [
    "G = df_to_graph(df)\n",
    "paths = graph_to_paths(G=G)\n",
    "print(f\"The graph was decomposed into {len(paths)} paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting the entire skeleton/neuron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<Shapes layer 'Skeleton 2 [1]' at 0x14f499208>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "# it is important that the number of paths put into 'data=' is at the most 1024\n",
    "viewer.add_points(data=np.concatenate(paths)[804:], edge_width=2, edge_color='white', name='Skeleton 2')\n",
    "viewer.add_shapes(data=paths, shape_type='path', edge_color='white', name='Skeleton 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Bounding Box Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a bounding box based on a particular vertex of interest in order to get a group of neurons neighboring the vertex of interest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading: 100%|██████████| 3/3 [00:00<00:00, 25.82it/s]\n\n\n\nDownloading: 100%|██████████| 4/4 [00:00<00:00, 33.75it/s]\n\n\n"
    }
   ],
   "source": [
    "# Create an NGL session to get the bounding box\n",
    "ngl_sess = NeuroglancerSession(\n",
    "    url=\"file://\"+dest_dir, \n",
    "    url_segments=\"file://\"+dest_dir_segments,\n",
    "    mip=1\n",
    ")\n",
    "img, bbbox, vox = ngl_sess.pull_chunk(seg_id, v_id, 1, 1, 1)\n",
    "bbox = bbbox.to_list()\n",
    "box = (bbox[:3], bbox[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting all the coordinates of the group surrounding the vertex of interest using get_sub_neuron()**  \n",
    "Note: data correction step necessary due to recentering in function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_sub = get_sub_neuron(G, box)\n",
    "\n",
    "# preventing the re-centring of nodes to the bounding box corner (origin of the new coordinate frame)\n",
    "for id in list(G_sub.nodes):\n",
    "    G_sub.nodes[id][\"x\"] = G_sub.nodes[id][\"x\"] + box[0][0]\n",
    "    G_sub.nodes[id][\"y\"] = G_sub.nodes[id][\"y\"] + box[0][1]\n",
    "    G_sub.nodes[id][\"z\"] = G_sub.nodes[id][\"z\"] + box[0][2]\n",
    "    \n",
    "paths_sub = graph_to_paths(G_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting vertex and vertex neighborhood**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[195.7467181  205.4302048   69.07140825]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<Points layer 'vertex' at 0x1606de908>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# grab the coordinates of the vertex from the skeleon \n",
    "cv_skel = CloudVolume(s3_path, mip=mip)\n",
    "skel = cv_skel.skeleton.get(seg_id)\n",
    "vertex = skel.vertices[v_id]/cv_skel.scales[mip][\"resolution\"]\n",
    "print(vertex)\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(np.squeeze(np.array(img)))\n",
    "viewer.add_points(data=np.concatenate(paths_sub), edge_width=2, edge_color='blue', name='Skeleton 2')\n",
    "viewer.add_shapes(data=paths_sub, shape_type='path', edge_color='blue', name='Neighborhood',edge_width=5)\n",
    "\n",
    "# display vertex\n",
    "viewer.add_points(data=np.array(vertex), edge_width=5, edge_color='green', name='vertex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbors Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[195.7467181  205.4302048   69.07140825]\n469\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     sample  structure      x      y     z    r  parent\n469     434          0  196.0  205.0  69.0  1.0     431",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n      <th>structure</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>r</th>\n      <th>parent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>469</th>\n      <td>434</td>\n      <td>0</td>\n      <td>196.0</td>\n      <td>205.0</td>\n      <td>69.0</td>\n      <td>1.0</td>\n      <td>431</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# grab the coordinates of the vertex from the skeleon \n",
    "cv_skel = CloudVolume(s3_path, mip=mip)\n",
    "skel = cv_skel.skeleton.get(seg_id)\n",
    "vertex = skel.vertices[v_id]/cv_skel.scales[mip][\"resolution\"]\n",
    "print(vertex)\n",
    "\n",
    "# figure out where the vertex information is stored in the dataframe returned by read_s3\n",
    "x, y, z = np.round((vertex))[0], np.round((vertex))[1], np.round((vertex))[2]\n",
    "slice_df = (df[(df.x == x)&(df.y==y)&(df.z==z)])\n",
    "v_idx = np.where((df.x == x)&(df.y==y)&(df.z==z))\n",
    "v_idx = v_idx[0][0]\n",
    "print(v_idx)\n",
    "slice_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On another napari window, plot again the entire neuron/skeleton.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<Shapes layer 'skeleton' at 0x150b65358>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_points(data=np.concatenate(paths, axis=0)[1024:], edge_width=2, edge_color='white', name='all_points')\n",
    "viewer.add_shapes(data=paths, shape_type='path', edge_color='white', edge_width=3, name='skeleton')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the coordinates of the neighobrs around vertex of interest using get_bfs_subgraph() and graphs_to_paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_id_pos = v_idx  # the row index/number of the data frame\n",
    "depth = 10  # the depth up to which the graph must be constructed\n",
    "\n",
    "G_bfs=get_bfs_subgraph(G, v_id_pos, depth, df=df)  # perform Breadth first search to obtain a graph of interest\n",
    "paths_bfs = graph_to_paths(G=G_bfs[0])  # obtain all the paths for visualization purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the vertex and vertex neighborhood**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1516c732dc52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnapari\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'orange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bfs_vertex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# display all neighbors around vertex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/brainlit/lib/python3.7/site-packages/napari/components/add_layers_mixin.py\u001b[0m in \u001b[0;36madd_points\u001b[0;34m(self, data, properties, symbol, size, edge_width, edge_color, edge_color_cycle, edge_colormap, edge_contrast_limits, face_color, face_color_cycle, face_colormap, face_contrast_limits, n_dimensional, name, metadata, scale, translate, opacity, blending, visible)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisible\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         )\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/brainlit/lib/python3.7/site-packages/napari/components/add_layers_mixin.py\u001b[0m in \u001b[0;36madd_layer\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     def add_image(\n",
      "\u001b[0;32m~/miniconda3/envs/brainlit/lib/python3.7/site-packages/napari/components/viewer_model.py\u001b[0m in \u001b[0;36mreset_view\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mquaternion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             self.events.reset_view(\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquaternion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquaternion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             )\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/brainlit/lib/python3.7/site-packages/napari/utils/event.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/brainlit/lib/python3.7/site-packages/napari/utils/event.py\u001b[0m in \u001b[0;36m_invoke_callback\u001b[0;34m(self, cb, event)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_callback_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                 \u001b[0mcb_event\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             )\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/brainlit/lib/python3.7/site-packages/napari/utils/event.py\u001b[0m in \u001b[0;36m_invoke_callback\u001b[0;34m(self, cb, event)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_invoke_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             _handle_exception(\n",
      "\u001b[0;32m~/miniconda3/envs/brainlit/lib/python3.7/site-packages/napari/_qt/qt_viewer.py\u001b[0m in \u001b[0;36m_on_reset_view\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_quaternion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;31m# Assumes default camera has the same properties as PanZoomCamera\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/brainlit/lib/python3.7/site-packages/vispy/scene/cameras/perspective.py\u001b[0m in \u001b[0;36mscale_factor\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/brainlit/lib/python3.7/site-packages/vispy/scene/cameras/base_camera.py\u001b[0m in \u001b[0;36mview_changed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;31m# Do the actual update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/brainlit/lib/python3.7/site-packages/vispy/scene/cameras/perspective.py\u001b[0m in \u001b[0;36m_update_transform\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mfy\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_projection_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# assemble complete transform mapping to viewbox bounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/brainlit/lib/python3.7/site-packages/vispy/scene/cameras/perspective.py\u001b[0m in \u001b[0;36m_update_projection_transform\u001b[0;34m(self, fx, fy)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fov\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_projection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ortho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actual_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distance\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/brainlit/lib/python3.7/site-packages/vispy/visuals/transforms/linear.py\u001b[0m in \u001b[0;36mset_ortho\u001b[0;34m(self, l, r, b, t, n, f)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mFar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \"\"\"\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mortho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/brainlit/lib/python3.7/site-packages/vispy/util/transforms.py\u001b[0m in \u001b[0;36mortho\u001b[0;34m(left, right, bottom, top, znear, zfar)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mOrthographic\u001b[0m \u001b[0mprojection\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottom\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mznear\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mzfar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x,y,z = df.iloc[v_id_pos]['x'], df.iloc[v_id_pos]['y'], df.iloc[v_id_pos]['z']\n",
    "\n",
    "# display vertex\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "\n",
    "viewer.add_points(data=np.array([x,y,z]), edge_width=5, edge_color='orange', name='bfs_vertex')\n",
    "\n",
    "# display all neighbors around vertex\n",
    "viewer.add_points(data=np.concatenate(paths_bfs), edge_color='red', edge_width=2, name='bfs_points')\n",
    "viewer.add_shapes(data=paths_bfs, shape_type='path', edge_color='red', edge_width=3, name='bfs_sub_skeleton')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the output of both methods overlaid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create new napari window**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Shapes layer 'full_skeleton' at 0x186a1e2d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_points(data=np.concatenate(paths, axis=0)[1024:], edge_width=2, edge_color='white', name='all_points')\n",
    "viewer.add_shapes(data=paths, shape_type='path', edge_color='white', edge_width=3, name='full_skeleton')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot vertices and neighborhoods of each method on the same napari window to compare method outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Shapes layer 'bfs_skeleton_lines' at 0x18351db50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display vertex of the boundary method\n",
    "viewer.add_points(data=np.array(vertex), edge_width=5, edge_color='green', name='boundary_vertex')\n",
    "\n",
    "# display all neighbors around vertex of boundary method\n",
    "viewer.add_points(data=np.concatenate(paths_sub), edge_width=2, edge_color='blue', name='boundary_skeleton_pts')\n",
    "viewer.add_shapes(data=paths_sub, shape_type='path', edge_color='blue', name='boundary_skeleton_lines',edge_width=5)\n",
    "\n",
    "# display vertex of the bfs method\n",
    "x,y,z = df.iloc[v_id_pos]['x'], df.iloc[v_id_pos]['y'], df.iloc[v_id_pos]['z']\n",
    "viewer.add_points(data=np.array([x,y,z]), edge_width=5, edge_color='orange', name='bfs_vertex')\n",
    "\n",
    "# display all neighbors around vertex of bfs method\n",
    "viewer.add_points(data=np.concatenate(paths_bfs), edge_color='red', edge_width=2, name='bfs_skeleton_pts')\n",
    "viewer.add_shapes(data=paths_bfs, shape_type='path', edge_color='red', edge_width=3, name='bfs_skeleton_lines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}