{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import napari\n",
    "from os.path import exists\n",
    "from brainlit.utils.session import NeuroglancerSession\n",
    "from cloudvolume.exceptions import SkeletonDecodeError\n",
    "from napari_animation import AnimationWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 9 #0,2,3,4,7,9\n",
    "janelia = False\n",
    "\n",
    "im_path = \"/Users/thomasathey/Documents/mimlab/mouselight/input/images/first10_quantitative/images/2018-08-01_\" + str(num) + \"_first10_quantitative.tif\"\n",
    "im = Path(im_path)\n",
    "img = io.imread(im, plugin=\"tifffile\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "\n",
    "# read coords\n",
    "if janelia:\n",
    "    csv_path = \"/Users/thomasathey/Documents/mimlab/mouselight/input/images/first10_quantitative/voxel_coords.csv\"\n",
    "    coords = np.genfromtxt(csv_path, delimiter=',')\n",
    "    coords = coords[10*num:10*(num+1)].astype(int)\n",
    "    soma_coords = [list(coords[0,:])]\n",
    "    axon_coords = [list(coords[-1,:])]\n",
    "else:\n",
    "    csv_path = \"/Users/thomasathey/Documents/mimlab/mouselight/input/images/first10_quantitative/my_points/points_\" + str(num) + \".csv\"\n",
    "    coords = np.genfromtxt(csv_path, delimiter=',')\n",
    "    coords = coords[1:].astype(int)\n",
    "    coords = coords[:,1:]\n",
    "    soma_coords = [list(coords[-1,:])]\n",
    "    axon_coords = [list(coords[0,:])]\n",
    "\n",
    "coords_list = list(coords)\n",
    "coords_list = [list(c) for c in coords_list]\n",
    "print(f\"coords shape: {coords.shape}\")\n",
    "\n",
    "if num == 0:\n",
    "    soma_coords += [[226, 643, 92], [233, 459, 120], [439, 500, 62]]\n",
    "elif num == 7:\n",
    "    soma_coords += [[335, 178, 39], [1, 418, 322]]\n",
    "\n",
    "print(f\"Soma coords: {soma_coords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 invalid\n",
      "#1 invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton # 2 exists\n",
      "#3 invalid\n",
      "#4 invalid\n",
      "#5 invalid\n",
      "#6 invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton # 7 exists\n",
      "#8 invalid\n",
      "#9 invalid\n",
      "#10 invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton # 11 exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "Downloading: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (282, 308, 282)\n"
     ]
    }
   ],
   "source": [
    "dir = \"s3://open-neurodata/brainlit/brain1\"\n",
    "dir_segments = \"s3://open-neurodata/brainlit/brain1_segments\"\n",
    "\n",
    "ngl_sess = NeuroglancerSession(mip = 0, url = dir, url_segments=dir_segments)\n",
    "\n",
    "num_goal = 2\n",
    "num = -1\n",
    "skel_id = 0\n",
    "\n",
    "while num < num_goal:\n",
    "    try:\n",
    "        ngl_sess.pull_vertex_list(skel_id, [0], 1)\n",
    "        print(f\"Skeleton # {skel_id} exists\")\n",
    "        num += 1\n",
    "    except SkeletonDecodeError:\n",
    "        print(f\"#{skel_id} invalid\")\n",
    "    skel_id += 1\n",
    "\n",
    "img, bbox, vox = ngl_sess.pull_vertex_list(skel_id-1, [0,1,2,3,4,5,6,7,8,9], [50,50,15])\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "coords_list = vox\n",
    "soma_coords = [coords_list[0]]\n",
    "axon_coords = [coords_list[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 42/42 [00:00<00:00, 68839.69it/s]\n",
      "\n",
      "\n",
      "Drawing edges...: 100%|██████████| 42/42 [00:00<00:00, 35688.97it/s]\n",
      "Downloading: 100%|██████████| 1/1 [00:05<00:00,  5.40s/it]\n",
      "Downloading: 100%|██████████| 72/72 [00:02<00:00, 35.92it/s]\n",
      "/Users/thomasathey/Documents/mimlab/mouselight/docs_env/lib/python3.8/site-packages/napari_animation/_qt/keyframeslist_widget.py:156: FutureWarning: Themes were changed to use evented model with Pydantic's color type rather than the `rgb(x, y, z)`. You can get the old color by calling `color.as_rgb()`. The `as_dict=True` option will be removed in 0.X.X\n",
      "  self.setStyleSheet(template(qss_template, **get_theme(theme_name)))\n"
     ]
    }
   ],
   "source": [
    "from skimage import measure\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "new_true = np.multiply(np.array(coords_list), [0.3,0.3,1])\n",
    "new_true_resample = resample(new_true)\n",
    "new_true_resample = np.flip(new_true_resample, axis=0)\n",
    "\n",
    "app_reflect_y = False\n",
    "\n",
    "swcs = os.listdir(\"/Users/thomasathey/Documents/mimlab/mouselight/input/images/firstn_quantitative/gtree_2/\")\n",
    "swcs_valid = []\n",
    "for swc in swcs:\n",
    "    if swc.split(\"_\")[0] == str(num):\n",
    "        swcs_valid.append(\"/Users/thomasathey/Documents/mimlab/mouselight/input/images/firstn_quantitative/gtree_2/\" + swc)\n",
    "\n",
    "#\n",
    "gtree_path, gtree_mask = read_swc(swcs_valid,\n",
    "                    np.multiply(axon_coords[0], [0.3,0.3,1]), np.multiply(soma_coords[0], [0.3,0.3,1]), reflect_y=app_reflect_y)\n",
    "#new_gtree = np.multiply(np.array(gtree_path), [0.3,0.3,1])\n",
    "new_gtree = resample(gtree_path)\n",
    "\n",
    "# gtree_mask_dilate = 0*gtree_mask\n",
    "# for unq in tqdm(np.unique(gtree_mask)):\n",
    "#     if unq == 0:\n",
    "#         continue\n",
    "#     mask_unq = gtree_mask == unq\n",
    "#     mask_unq = ndi.binary_dilation(mask_unq, iterations=2)\n",
    "\n",
    "#     gtree_mask_dilate[mask_unq > 0] += unq\n",
    "\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(img, scale=[0.3,0.3,1])\n",
    "viewer.add_labels(gtree_mask)\n",
    "#viewer.add_labels(gtree_mask_dilate>0, scale=[0.3,0.3,1])\n",
    "viewer.add_shapes(new_gtree, shape_type='path', edge_width=1, edge_color='red', name=\"gtree\")\n",
    "viewer.add_shapes(new_true_resample, shape_type='path', edge_width=1, edge_color='green', name=\"truth\")\n",
    "viewer.add_points([axon_coords[0], soma_coords[0]], size=2, scale=[0.3,0.3,1])\n",
    "animation_widget = AnimationWidget(viewer)\n",
    "viewer.window.add_dock_widget(animation_widget, area=\"right\")\n",
    "viewer.camera.angles = [0, 90, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_path = \"/Users/thomasathey/Documents/mimlab/mouselight/input/images/firstn_quantitative/manual/\" + str(num) + \".swc\"\n",
    "coords_list = []\n",
    "with open(manual_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        if line[0] != \"#\":\n",
    "            parts = line.split()\n",
    "            coord = [float(parts[p]) for p in range(2,5)]\n",
    "            coord = [int(c) for c in coord]\n",
    "            coord.reverse()\n",
    "            coords_list.append(coord)\n",
    "coords_list.reverse()\n",
    "coords_list = np.array(coords_list)\n",
    "soma_coords = [coords_list[0]]\n",
    "axon_coords = [coords_list[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(img, scale=[0.3,0.3,1])\n",
    "viewer.add_shapes(coords_list, shape_type='path', edge_width=2, edge_color='green', name=\"truth\", scale=[0.3,0.3,1])\n",
    "#viewer.add_shapes(new_app, shape_type='path', edge_width=2, edge_color='red', name=\"truth\")\n",
    "\n",
    "viewer.add_points(soma_coords, face_color='orange', size=8, scale=[0.3,0.3,1])\n",
    "viewer.add_points(axon_coords, face_color='red', size=8, scale=[0.3,0.3,1])\n",
    "viewer.camera.angles = [0, -90, -90]\n",
    "napari.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save as zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_path = \"/Users/thomasathey/Documents/mimlab/mouselight/input/images/firstn_quantitative/zarr/\" + str(num) + \".zarr\"\n",
    "\n",
    "z = zarr.zeros(img.shape, chunks=img.shape, dtype=img.dtype)\n",
    "z = img\n",
    "zarr.save(zarr_path, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.algorithms.generate_fragments.state_generation import state_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = state_generation(image_path=\"/Users/thomasathey/Documents/mimlab/mouselight/input/images/firstn_quantitative/zarr/\" + str(num) + \".zarr\",\n",
    "        ilastik_program_path=\"/Applications/ilastik-1.3.3post3-OSX.app/Contents/ilastik-release/run_ilastik.sh\",\n",
    "        ilastik_project_path=\"/Users/thomasathey/Documents/mimlab/mouselight/octopus_experiment/octopus_exp.ilp\",\n",
    "        chunk_size=img.shape,\n",
    "        soma_coords=soma_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.predict(data_bin=\"/Users/thomasathey/Documents/mimlab/mouselight/input/images/first10_quantitative/zarr/misc/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.compute_frags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.compute_soma_lbls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.compute_image_tiered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.compute_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.compute_edge_weights()\n",
    "viterbrain = sg.viterbrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/Users/thomasathey/Documents/mimlab/mouselight/input/images/firstn_quantitative/zarr/' + str(num) + '_viterbrain.pickle', 'rb') as handle:\n",
    "    viterbrain = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb_path = viterbrain.shortest_path(axon_coords[0], soma_coords[0])\n",
    "vb_path = [list(coord) for coord in vb_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(img)\n",
    "viewer.add_shapes(vb_path, shape_type='path', edge_width=2, edge_color='red', name=\"viterbrain\")\n",
    "viewer.add_shapes(coords_list, shape_type='path', edge_width=2, edge_color='green', name=\"truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load other paths and resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from cloudvolume import Skeleton\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from brainlit.viz import Bresenham3D\n",
    "import similaritymeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_swc(file_paths, start_pt, end_pt, switch_axes = True, reflect_y = True, factor = [1,1,1]):\n",
    "    cur_base = 0\n",
    "    vert_cumulative = []\n",
    "    g = nx.Graph()\n",
    "    mask = 0*img\n",
    "\n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            swc = f.read()\n",
    "        skel = Skeleton.from_swc(swc)\n",
    "\n",
    "        verts = np.array(skel.vertices)\n",
    "\n",
    "        if switch_axes:\n",
    "            verts[:, [0,2]] = verts[:, [2,0]]\n",
    "        if reflect_y:\n",
    "            verts[:,1] = im_og.shape[1] - 1 - verts[:,1]\n",
    "        verts = np.multiply(verts, factor)\n",
    "        skel.vertices = verts\n",
    "        vert_cumulative.append(verts)\n",
    "\n",
    "        num_verts = skel.vertices.shape[0]\n",
    "        g.add_nodes_from(np.arange(num_verts)+cur_base)\n",
    "        for e in tqdm(skel.edges):\n",
    "            g.add_edge(e[0]+cur_base,e[1]+cur_base)\n",
    "\n",
    "        cur_base += num_verts\n",
    "\n",
    "        #make mask\n",
    "        skel_mask = 0*img\n",
    "\n",
    "        for edge in tqdm(skel.edges, desc='Drawing edges...'):\n",
    "            pt1 = skel.vertices[edge[0],:].astype(int)\n",
    "            pt2 = skel.vertices[edge[1],:].astype(int)\n",
    "            xs, ys, zs = Bresenham3D(int(pt1[0]), int(pt1[1]), int(pt1[2]),int(pt2[0]), int(pt2[1]), int(pt2[2]))\n",
    "            skel_mask[xs, ys, zs] = 1\n",
    "        \n",
    "        mask[skel_mask > 0] = i+1\n",
    "\n",
    "    vert_cumulative = np.concatenate(vert_cumulative, axis=0)\n",
    "    # find path\n",
    "    amins, _ = pairwise_distances_argmin_min(np.array([end_pt]), vert_cumulative)\n",
    "    soma_id = amins[0]\n",
    "\n",
    "    amins, _ = pairwise_distances_argmin_min(np.array([start_pt]), vert_cumulative)\n",
    "    axon_id = amins[0]\n",
    "        \n",
    "    try:\n",
    "        graph_path = nx.shortest_path(g, source=axon_id, target=soma_id)\n",
    "    except:\n",
    "        graph_path = [axon_id]\n",
    "\n",
    "    path = []\n",
    "    for id in graph_path:\n",
    "        path.append(vert_cumulative[id, :])\n",
    "    path = np.array(path)\n",
    "    path = np.concatenate(([start_pt], path, [end_pt]), axis=0)\n",
    "\n",
    "    return path, mask\n",
    "\n",
    "def resample(path, spacing = 1):\n",
    "    new_path = []\n",
    "    for n in np.arange(path.shape[0]):\n",
    "        pt1 = path[n-1:n,:]\n",
    "        pt2 = path[n:n+1,:]\n",
    "\n",
    "        new_path.append(pt1)\n",
    "        dist = np.linalg.norm(pt1-pt2)\n",
    "\n",
    "        if dist > 1:\n",
    "            ts = np.arange(0, dist , 5)\n",
    "            mid = np.zeros((len(ts)-1,3))\n",
    "            for i,t in enumerate(ts[1:]):\n",
    "                mid[i,:] = pt1 + (t/dist)*(pt2 -  pt1)\n",
    "            new_path.append(mid)\n",
    "    new_path.append(pt2)\n",
    "    new_path = np.concatenate(new_path)\n",
    "    return new_path\n",
    "\n",
    "def sd(pts1, pts2, substantial = False, verbose=False):\n",
    "    _, dists1 = pairwise_distances_argmin_min(pts1, pts2)\n",
    "    _, dists2 = pairwise_distances_argmin_min(pts2, pts1)\n",
    "    if verbose:\n",
    "        print(dists1)\n",
    "        print(dists2)\n",
    "    if substantial:\n",
    "        ddiv1 = np.mean(dists1[dists1 > 2])\n",
    "        ddiv2 = np.mean(dists2[dists2 > 2])\n",
    "        return np.mean([ddiv1, ddiv2])\n",
    "    else:\n",
    "        ddiv1 = np.mean(dists1)\n",
    "        ddiv2 = np.mean(dists2)\n",
    "        return np.mean([ddiv1, ddiv2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_true = np.multiply(np.array(coords_list), [0.3,0.3,1])\n",
    "new_true_resample = resample(new_true)\n",
    "new_true_resample = np.flip(new_true_resample, axis=0)\n",
    "new_viterbi = np.multiply(np.array(vb_path), [0.3,0.3,1])\n",
    "new_viterbi = resample(new_viterbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_reflect_y = False\n",
    "\n",
    "ad_path, _ = read_swc([\"/Users/thomasathey/Documents/mimlab/mouselight/input/images/firstn_quantitative/advantra/\" + str(num) + \".tif_Advantra.swc\"],\n",
    "                    axon_coords[0], soma_coords[0], reflect_y=app_reflect_y)\n",
    "new_ad = np.multiply(np.array(ad_path), [0.3,0.3,1])\n",
    "new_ad = resample(new_ad)\n",
    "\n",
    "app_reflect_y = False\n",
    "\n",
    "app_path, _ = read_swc([\"/Users/thomasathey/Documents/mimlab/mouselight/input/images/firstn_quantitative/app2/\" + str(num) + \".swc\"],\n",
    "                    axon_coords[0], soma_coords[0], reflect_y=app_reflect_y)\n",
    "new_app = np.multiply(np.array(app_path), [0.3,0.3,1])\n",
    "new_app = resample(new_app)\n",
    "\n",
    "app_reflect_y = False\n",
    "\n",
    "snake_path, _ = read_swc([\"/Users/thomasathey/Documents/mimlab/mouselight/input/images/firstn_quantitative/snake/\" + str(num) + \".tif_snake.swc\"],\n",
    "                    axon_coords[0], soma_coords[0], reflect_y=app_reflect_y)\n",
    "new_snake = np.multiply(np.array(snake_path), [0.3,0.3,1])\n",
    "new_snake = resample(new_snake)\n",
    "\n",
    "app_reflect_y = False\n",
    "\n",
    "swcs = os.listdir(\"/Users/thomasathey/Documents/mimlab/mouselight/input/images/firstn_quantitative/gtree/\")\n",
    "swcs_valid = []\n",
    "for swc in swcs:\n",
    "    if swc.split(\"_\")[0] == str(num):\n",
    "        swcs_valid.append(\"/Users/thomasathey/Documents/mimlab/mouselight/input/images/firstn_quantitative/gtree/\" + swc)\n",
    "gtree_path, gtree_mask = read_swc(swcs_valid,\n",
    "                    axon_coords[0], soma_coords[0], reflect_y=app_reflect_y)\n",
    "new_gtree = np.multiply(np.array(gtree_path), [0.3,0.3,1])\n",
    "new_gtree = resample(new_gtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(img, scale=[0.3,0.3,1])\n",
    "viewer.add_shapes(new_viterbi, shape_type='path', edge_width=1, edge_color='red', name=\"viterbrain\")\n",
    "viewer.add_shapes(new_true_resample, shape_type='path', edge_width=1, edge_color='green', name=\"truth\")\n",
    "viewer.add_shapes(new_app, shape_type='path', edge_width=1, edge_color='blue', name=\"app2\")\n",
    "viewer.add_shapes(new_ad, shape_type='path', edge_width=1, edge_color='blue', name=\"advantra\")\n",
    "viewer.add_shapes(new_snake, shape_type='path', edge_width=1, edge_color='blue', name=\"snake\")\n",
    "#viewer.add_shapes(new_gtree, shape_type='path', edge_width=2, edge_color='orange', name=\"gtree\")\n",
    "animation_widget = AnimationWidget(viewer)\n",
    "viewer.window.add_dock_widget(animation_widget, area=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Viterbi: Frechet: {similaritymeasures.frechet_dist(new_true_resample, new_viterbi)}, SSD: {sd(new_true_resample, new_viterbi, substantial = False)}\")\n",
    "print(f\"APP2: Frechet: {similaritymeasures.frechet_dist(new_true_resample, new_app)}, SSD: {sd(new_true_resample, new_app, substantial = False)}\")\n",
    "print(f\"Advantra: Frechet: {similaritymeasures.frechet_dist(new_true_resample, new_ad)}, SSD: {sd(new_true_resample, new_app, substantial = False)}\")\n",
    "print(f\"gtree: Frechet: {similaritymeasures.frechet_dist(new_true_resample, new_gtree)}, SSD: {sd(new_true_resample, new_gtree, substantial = False)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read my points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/Users/thomasathey/Documents/mimlab/mouselight/input/images/firstn_quantitative/manual/points_\" + str(num) + \".csv\"\n",
    "coords = np.genfromtxt(csv_path, delimiter=',')\n",
    "coords = coords[1:].astype(int)\n",
    "coords = coords[:,1:]\n",
    "soma_coords = [list(coords[-1,:])]\n",
    "axon_coords = [list(coords[0,:])]\n",
    "\n",
    "coords_list = list(coords)\n",
    "coords_list = [list(c) for c in coords_list]\n",
    "\n",
    "vb_path = viterbrain.shortest_path(axon_coords[0], soma_coords[0])\n",
    "vb_path = [list(coord) for coord in vb_path]\n",
    "\n",
    "new_true = np.multiply(np.array(coords_list), [0.3,0.3,1])\n",
    "new_true_resample = resample(new_true)\n",
    "new_viterbi = np.multiply(np.array(vb_path), [0.3,0.3,1])\n",
    "new_viterbi = resample(new_viterbi)\n",
    "\n",
    "app_reflect_y = False\n",
    "\n",
    "ad_path, _ = read_swc(\"/Users/thomasathey/Documents/mimlab/mouselight/input/images/firstn_quantitative/advantra/\" + str(num) + \".tif_Advantra.swc\",\n",
    "                    axon_coords[0], soma_coords[0], reflect_y=app_reflect_y)\n",
    "new_ad = np.multiply(np.array(ad_path), [0.3,0.3,1])\n",
    "new_ad = resample(new_ad)\n",
    "\n",
    "app_reflect_y = False\n",
    "\n",
    "app_path, _ = read_swc(\"/Users/thomasathey/Documents/mimlab/mouselight/input/images/firstn_quantitative/app2/\" + str(num) + \".swc\",\n",
    "                    axon_coords[0], soma_coords[0], reflect_y=app_reflect_y)\n",
    "new_app = np.multiply(np.array(app_path), [0.3,0.3,1])\n",
    "new_app = resample(new_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Viterbi: Frechet: {similaritymeasures.frechet_dist(new_true_resample, new_viterbi)}, SSD: {sd(new_true_resample, new_viterbi, substantial = False)}\")\n",
    "print(f\"APP2: Frechet: {similaritymeasures.frechet_dist(new_true_resample, new_app)}, SSD: {sd(new_true_resample, new_app, substantial = False)}\")\n",
    "print(f\"Advantra: Frechet: {similaritymeasures.frechet_dist(new_true_resample, new_ad)}, SSD: {sd(new_true_resample, new_app, substantial = False)}\")\n",
    "# print(f\"gtree: Frechet: {similaritymeasures.frechet_dist(new_true_resample, new_gtree)}, SSD: {sd(new_true_resample, new_gtree, substantial = False)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('docs_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
