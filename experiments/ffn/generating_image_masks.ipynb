{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils.Neuron_trace import NeuronTrace\n",
    "from brainlit.viz.visualize import napari_viewer\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "from pathlib import Path\n",
    "from brainlit.algorithms.image_processing import Bresenham3D\n",
    "from brainlit.utils.benchmarking_params import brain_offsets, vol_offsets, scales, type_to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all the benchmarking images from local paths\n",
    "# all the paths of gfp images are saved in variable gfp_files\n",
    "# the folder of output masks is in the same folder where the folder of benchmarking data is\n",
    "base_dir = Path(\"D:/Study/Nuero Data Design/brainlit\")\n",
    "data_dir = base_dir / \"benchmarking_datasets\"\n",
    "im_dir = data_dir / \"Images\"\n",
    "mask_dir = base_dir / \"benchmarking_masks\"\n",
    "gfp_files = list(im_dir.glob(\"**/*.tif\"))\n",
    "swc_base_path = data_dir / \"Manual-GT\"\n",
    "save = True\n",
    "\n",
    "for im_num, im_path in enumerate(gfp_files):\n",
    "    # loading one gfp image\n",
    "    print(str(im_path))\n",
    "    im = io.imread(im_path, plugin=\"tifffile\")\n",
    "    im = np.swapaxes(im, 0, 2)\n",
    "    \n",
    "    file_name = im_path.parts[-1][:-8]\n",
    "    \n",
    "    f = im_path.parts[-1][:-8].split(\"_\")\n",
    "    image = f[0]\n",
    "    date = type_to_date[image]\n",
    "    num = int(f[1])\n",
    "\n",
    "    scale = scales[date]\n",
    "    brain_offset = brain_offsets[date]\n",
    "    vol_offset = vol_offsets[date][num]\n",
    "    im_offset = np.add(brain_offset, vol_offset)\n",
    "\n",
    "    # loading all the .swc files corresponding to the image\n",
    "    # all the paths of .swc files are saved in variable swc_files\n",
    "    lower = int(np.floor((num - 1) / 5) * 5 + 1)\n",
    "    upper = int(np.floor((num - 1) / 5) * 5 + 5)\n",
    "    dir1 = date + \"_\" + image + \"_\" + str(lower) + \"-\" + str(upper)\n",
    "    dir2 = date + \"_\" + image + \"_\" + str(num)\n",
    "    swc_path = swc_base_path / dir1 / dir2\n",
    "    swc_files = list(swc_path.glob(\"**/*.swc\"))\n",
    "\n",
    "    paths_total = []\n",
    "    labels_total = np.zeros(im.shape)\n",
    "    \n",
    "    # generate paths and save them into paths_total\n",
    "    for swc_num, swc in enumerate(swc_files):\n",
    "        if \"cube\" in swc.parts[-1]:\n",
    "            # skip the bounding box swc\n",
    "            continue\n",
    "        print(swc)\n",
    "        \n",
    "        swc_trace = NeuronTrace(path=swc)\n",
    "        paths = swc_trace.get_paths()\n",
    "        swc_offset, _, _, _ = swc_trace.get_df_arguments()\n",
    "        offset_diff = np.subtract(swc_offset, im_offset)\n",
    "        \n",
    "        #df, swc_offset, _, _, _ = read_swc(swc)\n",
    "        #offset_diff = np.subtract(swc_offset, im_offset)\n",
    "        #G = df_to_graph(df)\n",
    "        #paths = graph_to_paths(G)\n",
    "\n",
    "        # for every path in that swc\n",
    "        for path_num, p in enumerate(paths):\n",
    "            pvox = (p + offset_diff) / (scale) * 1000\n",
    "            paths_total.append(pvox)\n",
    "    \n",
    "    # generate labels by using paths\n",
    "    for path_voxel in paths_total:\n",
    "        for voxel_num, voxel in enumerate(path_voxel):\n",
    "            if voxel_num == 0:\n",
    "                continue\n",
    "            voxel_prev = path_voxel[voxel_num-1,:]\n",
    "            xs,ys,zs = Bresenham3D(int(voxel_prev[0]), int(voxel_prev[1]), int(voxel_prev[2]),int(voxel[0]), int(voxel[1]), int(voxel[2]))\n",
    "            for x,y,z in zip(xs,ys,zs):\n",
    "                vox = np.array((x,y,z))\n",
    "                if (vox >= 0).all() and (vox < im.shape).all():\n",
    "                    labels_total[x,y,z] = 1  \n",
    "    \n",
    "    label_flipped = labels_total*0\n",
    "    label_flipped[labels_total==0] = 1\n",
    "    dists = distance_transform_edt(label_flipped, sampling = scale)\n",
    "    labels_total[dists <= 1000] = 1\n",
    "    \n",
    "    if save:\n",
    "        im_file_name = file_name + \"_mask.tif\"\n",
    "        out_file = mask_dir / im_file_name\n",
    "        io.imsave(out_file, labels_total, plugin=\"tifffile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking whether masks can be loaded\n",
    "show_napari = False\n",
    "mask_files = list(mask_dir.glob(\"**/*.tif\"))\n",
    "\n",
    "for im_num, im_path in enumerate(gfp_files):\n",
    "    im = io.imread(im_path, plugin=\"tifffile\")\n",
    "    im = np.swapaxes(im, 0, 2)\n",
    "    \n",
    "    file_name = im_path.parts[-1][:-8]\n",
    "    mask_file = file_name + \"_mask.tif\"\n",
    "    mask_path = mask_dir / mask_file\n",
    "    mask = io.imread(mask_path, plugin=\"tifffile\")\n",
    "    \n",
    "    print(\"loading the mask of\", file_name, \"...\")\n",
    "    if show_napari:\n",
    "        napari_viewer(im, labels=mask, label_name=\"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
